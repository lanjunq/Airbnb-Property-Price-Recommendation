{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airbnb Price Recommendation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzZtplnBcMySGf0NMxuLKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lanjunq/Airbnb-Property-Price-Recommendation/blob/master/Airbnb_Price_Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iztPfqW5ZpGT",
        "colab_type": "text"
      },
      "source": [
        "# CIS 519 Final Project - Airbnb Price Recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLv950uNT_cJ",
        "colab_type": "text"
      },
      "source": [
        "# 1. Import Data and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBIvItXFVYJV",
        "colab_type": "text"
      },
      "source": [
        "## Import Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RwhW3oIT3sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import glob\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from joblib import dump, load\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrhtVCpqUByA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/Shared\\ drives/CIS\\ 519\\ Project\\ -\\ Airbnb\\ Pricing\\ Recommendation/data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0opG01RUD37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a raw data dictionary\n",
        "import glob\n",
        "import os\n",
        "\n",
        "data_sources = glob.glob('*')\n",
        "data_dict = dict()\n",
        "for source in data_sources:\n",
        "  data_city = os.listdir(source)\n",
        "  data_dict[source] = dict()\n",
        "\n",
        "  for city in data_city:\n",
        "    data_file = os.listdir(source + '/' + city)\n",
        "    data_dict[source][city] = data_file\n",
        "\n",
        "# Visualize all data files\n",
        "for source in data_dict.keys():\n",
        "  print('Source: {}'.format(source))\n",
        "  for city in data_dict[source].keys():\n",
        "    print('\\tCity: {}'.format(city))\n",
        "    for raw_data in data_dict[source][city]:\n",
        "      print('\\t\\tFile: \\t {}'.format(raw_data))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pya1Xq-UFQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source = 'Inside_Airbnb'\n",
        "# city_ny = 'New_York'\n",
        "# city_la = \"Los_Angeles\"\n",
        "# f = 'listings.csv.gz'\n",
        "# ny_reviews_df = pd.read_csv( '{}/{}/{}'.format(source, 'New_York', f) )\n",
        "# la_reviews_df = pd.read_csv( '{}/{}/{}'.format(source, 'Los_Angeles', f) )\n",
        "# # ny_reviews_df.iloc[:, 40:].head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUCuVGI5UMkf",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuF6sXmaUOQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ny_reviews_df = pd.read_csv( '{}/{}/{}'.format(source, city_ny, f) )\n",
        "la_reviews_df = pd.read_csv( '{}/{}/{}'.format(source, city_la, f) )\n",
        "\n",
        "feature_selection = [\"id\", \"experiences_offered\", \"transit\", \"host_response_time\" , \"host_response_rate\" ,  \n",
        "                     \"host_acceptance_rate\",  \"host_is_superhost\", \"host_neighbourhood\", \"host_total_listings_count\",  \n",
        "                     \"host_verifications\",  \"host_identity_verified\" , \"neighbourhood_cleansed\" , \"neighbourhood_group_cleansed\" , \n",
        "                     \"zipcode\" , \"latitude\", \"longitude\",  \"property_type\", \"room_type\", \"accommodates\", \"bathrooms\", \"bedrooms\", \n",
        "                     \"beds\", \"bed_type\", \"amenities\", \"square_feet\", \"security_deposit\" , \"cleaning_fee\", \"guests_included\" , \"extra_people\" , \n",
        "                     \"minimum_nights\" , \"number_of_reviews\",  \"number_of_reviews_ltm\", \"review_scores_rating\" , \n",
        "                     \"review_scores_accuracy\",  \"review_scores_cleanliness\",  \"review_scores_checkin\" , \n",
        "                     \"review_scores_communication\",  \"review_scores_location\" , \"review_scores_value\", \"requires_license\" , \n",
        "                     \"instant_bookable\" ,  \"cancellation_policy\", \"price\" ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd58jyhVUQ_N",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Processing\n",
        "*   experiences_offered: none - 0, otherwise 1\n",
        "*   transits: nan - 0, otherwise 1\n",
        "*   host_response_time: 5 catogories, nan - most frequent (haven't hot-encoding)\n",
        "*   host_response_rate, host_acceptance_rate: convert str to float, kept nan for now\n",
        "*   host_id_superhost: nan - most frequent ('f'), 'f' - 0, 't' - 1\n",
        "*   host_neighbourhood: dropped\n",
        "*   host_total_listings_count: nan - 1 (most freq)\n",
        "*   host_verifications: dropped replaced by host_verifications_count: based on host_verifications: missing value - 0, otherwise: len\n",
        "*   host_identity_verified: nan - most frequent ('f'), 'f' - 0, 't' - 1\n",
        "*   neighbourhood_cleansed, neighbourhood_group_cleansed: kept & haven't done anything\n",
        "*   zipcode: missing value - fre, converted to 5-digit float\n",
        "*   latitude, longitude: kept as float\n",
        "*   property_type, bed_type, room_type: kept as str for now\n",
        "*   accommadates: no missing value, kept as number\n",
        "*   bathrooms, bedrooms,beds: replace nan with frequent num\n",
        "*   amenities\n",
        "*   amenities: dropped replaced by amenities_count: len of amenities\n",
        "*   square_feet: missing - freq (or avg? could try)\n",
        "*   security_deposit, cleaning_fee, extra_people - missing value - 0, then  get rid of ',' and '\\$' convert to float\n",
        "*   guests_included: no missing, kept as int\n",
        "*   minimum_nights, number_of_reviews, number_of_reviews_ltm: no missing, kept as int\n",
        "*   review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location, review_scores_value: missing replaced with 0 (?should this be avg? or 0?)\n",
        "*   requires_license, instant_bookable: 1 't'  0 'f'\n",
        "*   cancellation_policy: 6 categories\n",
        "*   price: get rid of ',' and '\\$' convert to float\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGwT_a35UTFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ny = ny_reviews_df[feature_selection]\n",
        "print(type(X_ny))\n",
        "print(X_ny.shape)\n",
        "X_ny.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZzofC4xUUfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_ny.isnull().sum(axis=0)/X_ny.shape[0])\n",
        "for i in range(43):\n",
        "#   if(i == 2 or i == 14 or i == 15 or i ==17 or i == 21):\n",
        "    print(\"the number of unique value of the column \" + str(feature_selection[i]) +\" is: \"+ str(len(X_ny[X_ny.columns[i]].unique())))\n",
        "    # print(\"unique valur is: \")\n",
        "    # print(ny_X[ny_X.columns[i]].unique())\n",
        "    #print(\"the most freq value is: \" + str(X_train[X_train.columns[i]].mode()) + \"\\n\")\n",
        "    # print(\"data type is: \" + str(type(X.columns[i])))\n",
        "    # print(\"the most freq value is: \" + str(ny_X[ny_X.columns[i]].value_counts().idxmax()) + \"\\n\")\n",
        "#   else:\n",
        "    # X_train[col_names[i]] = X_train[col_names[i]].astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHIb9Kw4UWDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature type conversion\n",
        "X_ny[\"experiences_offered\"] = X_ny[\"experiences_offered\"].apply(lambda x : 0 if(x == 'none') else 1)\n",
        "X_ny['transit'] = X_ny['transit'].apply(lambda x : 0 if(type(x) is float) else 1)\n",
        "X_ny['host_response_time'] = X_ny['host_response_time'].apply(lambda x : X_ny[\"host_response_time\"].value_counts().idxmax() if(type(x) is float) else x)\n",
        "X_ny['host_response_rate'] = X_ny['host_response_rate'].apply(lambda x : int(x.split('%')[0])/100 if(type(x) is not float) else x)\n",
        "X_ny['host_acceptance_rate'] = X_ny['host_acceptance_rate'].apply(lambda x : int(x.split('%')[0])/100 if(type(x) is not float) else x)\n",
        "X_ny['host_is_superhost'] = X_ny['host_is_superhost'].apply(lambda x : 'f' if(type(x) is float) else x)\n",
        "X_ny['host_is_superhost'] = X_ny['host_is_superhost'].apply(lambda x : 0 if(x == 'f') else 1)\n",
        "X_ny['host_total_listings_count'] =X_ny['host_total_listings_count'].apply(lambda x : 1.0 if(np.isnan(x)) else x)\n",
        "X_ny['host_verifications_count'] =X_ny['host_verifications'].apply(lambda x : 0 if(x == '[]') else x)\n",
        "X_ny['host_verifications_count'] = X_ny['host_verifications'].apply(lambda x : x if(type(x) is int) else len(x.split(',')))\n",
        "X_ny['host_identity_verified'] = X_ny['host_identity_verified'].apply(lambda x : 'f' if(type(x) is float) else x)\n",
        "X_ny['host_identity_verified'] = X_ny['host_identity_verified'].apply(lambda x : 0 if(x == 'f') else 1)\n",
        "X_ny['zipcode'] = X_ny['zipcode'].apply(lambda x : X_ny[\"zipcode\"].value_counts().idxmax() if(type(x) is float or x==' ')  else x)\n",
        "X_ny['zipcode'] = X_ny['zipcode'].apply(lambda x : x[3:] if('NY' in x or ' ' in x) else x)\n",
        "X_ny['zipcode'] = X_ny['zipcode'].apply(lambda x : x[:5] if(len(x)>5) else x)\n",
        "X_ny['zipcode'] = X_ny['zipcode'].apply(lambda x : float(x))\n",
        "# replace nan with frequent num for \"bathrooms\",\"bedrooms\",\"beds\" - don't know if the value means the number of bath or the type?\n",
        "X_ny['bathrooms'] = X_ny['bathrooms'].apply(lambda x : X_ny[\"bathrooms\"].value_counts().idxmax() if(np.isnan(x))  else x)\n",
        "X_ny['bedrooms'] = X_ny['bedrooms'].apply(lambda x : X_ny[\"bedrooms\"].value_counts().idxmax() if(np.isnan(x))  else x)\n",
        "X_ny['beds'] = X_ny['beds'].apply(lambda x : X_ny[\"beds\"].value_counts().idxmax() if(np.isnan(x))  else x)\n",
        "X_ny['amenities_count'] = X_ny['amenities'].apply(lambda x : x if(type(x) is int) else len(x.split(',')))\n",
        "X_ny[\"square_feet\"] = X_ny[\"square_feet\"].apply(lambda x : X_ny[\"square_feet\"].value_counts().idxmax() if(np.isnan(x))  else x)\n",
        "X_ny[\"security_deposit\"]=  X_ny[\"security_deposit\"].apply(lambda x : '$0' if(type(x) is float)  else x)\n",
        "X_ny[\"security_deposit\"]=  X_ny[\"security_deposit\"].apply(lambda x : x.replace(\",\",\"\"))\n",
        "X_ny[\"security_deposit\"]=  X_ny[\"security_deposit\"].apply(lambda x: float(x[1:]))\n",
        "X_ny[\"cleaning_fee\"]=  X_ny[\"cleaning_fee\"].apply(lambda x : '$0' if(type(x) is float)  else x)\n",
        "X_ny[\"cleaning_fee\"]=  X_ny[\"cleaning_fee\"].apply(lambda x : x.replace(\",\",\"\"))\n",
        "X_ny[\"cleaning_fee\"]= X_ny[\"cleaning_fee\"].apply(lambda x: float(x[1:]))\n",
        "X_ny[\"extra_people\"]=  X_ny[\"extra_people\"].apply(lambda x : '$0' if(type(x) is float)  else x)\n",
        "X_ny[\"extra_people\"]=  X_ny[\"extra_people\"].apply(lambda x : x.replace(\",\",\"\"))\n",
        "X_ny[\"extra_people\"]=  X_ny[\"extra_people\"].apply(lambda x: float(x[1:]))\n",
        "X_ny['minimum_nights'] = X_ny['minimum_nights'].apply(lambda x : 1 if(np.isnan(x))  else x)\n",
        "X_ny['number_of_reviews'] = X_ny['number_of_reviews'].apply(lambda x : 1 if(np.isnan(x))  else x)\n",
        "X_ny['number_of_reviews_ltm'] = X_ny['number_of_reviews_ltm'].apply(lambda x : 1 if(np.isnan(x))  else x)\n",
        "X_ny[\"review_scores_rating\"] = X_ny[\"review_scores_rating\"].apply(lambda x: 0.0 if(np.isnan(x)) else x)\n",
        "X_ny[\"review_scores_accuracy\"] = X_ny[\"review_scores_accuracy\"].apply(lambda x: 0.0 if(np.isnan(x)) else x)\n",
        "X_ny[\"review_scores_cleanliness\"] = X_ny[\"review_scores_cleanliness\"].apply(lambda x: 0.0 if(np.isnan(x)) else x)\n",
        "X_ny[\"review_scores_checkin\"] = X_ny[\"review_scores_checkin\"].apply(lambda x: 0.0 if(np.isnan(x)) else x)\n",
        "X_ny[\"review_scores_communication\"] = X_ny[\"review_scores_communication\"].apply(lambda x: 0.0 if(np.isnan(x)) else x)\n",
        "X_ny[\"review_scores_location\"] = X_ny[\"review_scores_location\"].apply(lambda x: 0.0 if(np.isnan(x)) else x)\n",
        "X_ny[\"review_scores_value\"] = X_ny[\"review_scores_value\"].apply(lambda x: 0.0 if(np.isnan(x)) else x)\n",
        "X_ny[\"requires_license\"] = X_ny[\"requires_license\"].apply(lambda x: 1 if(x == 't') else 0)\n",
        "X_ny[\"instant_bookable\"] = X_ny[\"requires_license\"].apply(lambda x: 1 if(x == 't') else 0)\n",
        "X_ny[\"price\"] = X_ny[\"price\"].apply(lambda x : '$0' if(type(x) is float)  else x)\n",
        "X_ny[\"price\"] = X_ny[\"price\"].apply(lambda x : x.replace(\",\",\"\"))\n",
        "X_ny[\"price\"] = X_ny[\"price\"].apply(lambda x: float(x[1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewI-OhhVUXHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#replace nan with avg for: host_response_rate, host_acceptance_rate\n",
        "avg_response_rate = X_ny[\"host_response_rate\"].sum()/(X_ny[\"host_response_rate\"].shape[0] - X_ny[\"host_response_rate\"].isna().sum())\n",
        "print(avg_response_rate)\n",
        "X_ny[\"host_response_rate\"] = X_ny[\"host_response_rate\"].apply(lambda x: avg_response_rate if(np.isnan(x)) else x)\n",
        "#\n",
        "avg_acceptance_rate= X_ny[\"host_acceptance_rate\"].sum()/(X_ny[\"host_acceptance_rate\"].shape[0] - X_ny[\"host_acceptance_rate\"].isna().sum())\n",
        "X_ny[\"host_acceptance_rate\"] = X_ny[\"host_acceptance_rate\"].apply(lambda x: avg_acceptance_rate if(np.isnan(x)) else x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_QqgWhjUX4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ny = X_ny.drop([\"host_neighbourhood\"], axis=1)\n",
        "X_ny = X_ny.drop([\"amenities\"], axis=1)\n",
        "X_ny = X_ny.drop([\"host_verifications\"], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxeZ3vfpUXrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save df as .csv\n",
        "X_ny.to_csv( '{}/{}/{}'.format(source, city_ny, \"cleaned_ny.csv\") ,index=False)\n",
        "\n",
        "# Read df from .csv\n",
        "X_ny = pd.read_csv( '{}/{}/{}'.format(source, city_ny, \"cleaned_ny.csv\"))\n",
        "print(X_ny.shape, '\\n', X_ny.dtypes)\n",
        "X_ny.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGTgPCBDUav1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_ny.isnull().sum(axis=0)/X_ny.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JrwobAbUbrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\nData Type:\")\n",
        "print(\"data shape: (\"+ str(X_ny.shape[0]) +\" , \" +str(X_ny.shape[1]) + \")\")\n",
        "print(X_ny.dtypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waGUcxNWUc1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"unique value of room_type is: \")\n",
        "print(X_ny[\"room_type\"].unique())\n",
        "print('\\n')\n",
        "\n",
        "print(\"unique value of bed_type is: \")\n",
        "print(X_ny[\"bed_type\"].unique())\n",
        "print('\\n')\n",
        "\n",
        "print(\"unique value of property_type is: \")\n",
        "print(X_ny[\"property_type\"].unique())\n",
        "print('\\n')\n",
        "\n",
        "print(\"unique value of cancellation_policy is: \")\n",
        "print(X_ny[\"cancellation_policy\"].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFzCPLCJUfP3",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing for LA Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Xaf7dNUelB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_la = la_reviews_df[feature_selection]\n",
        "print(type(X_la))\n",
        "print(X_la.shape)\n",
        "X_la.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP6q6hMyUknm",
        "colab_type": "text"
      },
      "source": [
        "One-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kwzJsmAUmUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ny = pd.read_csv( '{}/{}/{}'.format(source, city_ny, \"cleaned_ny.csv\"))\n",
        "X_la = pd.read_csv( '{}/{}/{}'.format(source, city_la, \"cleaned_la.csv\"))\n",
        "\n",
        "#onehot encoding\n",
        "#drop column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN__jnRYUm7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #data for visualization\n",
        "# ny = X_ny[[\"latitude\", \"longitude\",\"price\"]]\n",
        "# la = X_la[[\"latitude\", \"longitude\",\"price\"]]\n",
        "\n",
        "# # display(ny.head(5))\n",
        "# # display(la.head(5))\n",
        "\n",
        "# ny.to_csv( '{}/{}/{}'.format(source, city_ny, \"ny_price.csv\") ,index=False)\n",
        "# la.to_csv( '{}/{}/{}'.format(source, city_la, \"la_price.csv\") ,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1_MwYbFUnzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categoorical_ny = X_ny[[\"host_response_time\",\"neighbourhood_group_cleansed\", \"property_type\",\"bed_type\",\"room_type\",\"cancellation_policy\"]].reset_index(drop=True)\n",
        "categoorical_la = X_la[[\"host_response_time\",\"neighbourhood_group_cleansed\", \"property_type\",\"bed_type\",\"room_type\",\"cancellation_policy\"]].reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxrdQ24eUqIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ny = pd.get_dummies(X_ny, columns=[\"host_response_time\"])\n",
        "X_la = pd.get_dummies(X_la, columns=[\"host_response_time\"])\n",
        "\n",
        "X_ny = pd.get_dummies(X_ny, columns=[\"neighbourhood_group_cleansed\"])\n",
        "X_la = pd.get_dummies(X_la, columns=[\"neighbourhood_group_cleansed\"])\n",
        "\n",
        "X_ny = pd.get_dummies(X_ny, columns=[\"property_type\"])\n",
        "X_la = pd.get_dummies(X_la, columns=[\"property_type\"])\n",
        "\n",
        "X_ny = pd.get_dummies(X_ny, columns=[\"room_type\"])\n",
        "X_la = pd.get_dummies(X_la, columns=[\"room_type\"])\n",
        "\n",
        "X_ny = pd.get_dummies(X_ny, columns=[\"bed_type\"])\n",
        "X_la = pd.get_dummies(X_la, columns=[\"bed_type\"])\n",
        "\n",
        "X_ny = pd.get_dummies(X_ny, columns=[\"cancellation_policy\"])\n",
        "X_la = pd.get_dummies(X_la, columns=[\"cancellation_policy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2645B2CzUrOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ny.to_csv( '{}/{}/{}'.format(source, city_ny, \"cleaned_ny_encoding.csv\") ,index=False)\n",
        "X_la.to_csv( '{}/{}/{}'.format(source, city_la, \"cleaned_la_encoding.csv\") ,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4vIwJdyUsvs",
        "colab_type": "text"
      },
      "source": [
        "## Train-Test Split\n",
        "Test is going to be 1/10 of the whole datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKMi708ZUu3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ny = pd.read_csv( '{}/{}/{}'.format(source, city_ny, \"cleaned_ny_encoding.csv\"))\n",
        "X_la = pd.read_csv( '{}/{}/{}'.format(source, city_la, \"cleaned_la_encoding.csv\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp4sPnP5Uwyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "ny_train, ny_test = train_test_split(X_ny, test_size=0.1, random_state=42, shuffle = True)\n",
        "la_train, la_test = train_test_split(X_la, test_size=0.1, random_state=42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4fii7IpUx6R",
        "colab_type": "text"
      },
      "source": [
        "## Standardization and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFHc7EWzU0Kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ny_columns = list(ny_train.columns)\n",
        "la_columns = list(la_train.columns)\n",
        "ny_columns.remove(\"id\")\n",
        "la_columns.remove(\"id\")\n",
        "ny_columns.remove(\"price\")\n",
        "la_columns.remove(\"price\")\n",
        "category_ny = ny_columns[33:]\n",
        "category_la = la_columns[33:]\n",
        "category_ny.append(\"id\")\n",
        "category_ny.append(\"price\")\n",
        "category_la.append(\"id\")\n",
        "category_la.append(\"price\")\n",
        "print(category_ny)\n",
        "print(category_la)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7abcR2odU_hH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_ny_train = ny_train[category_ny].reset_index(drop=True)\n",
        "X_ny_train = ny_train.drop(category_ny, axis=1).reset_index(drop=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbolSeaoVAZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_la_train = la_train[category_la].reset_index(drop=True)\n",
        "X_la_train = la_train.drop(category_la, axis=1).reset_index(drop=True)\n",
        "\n",
        "y_ny_test = ny_test[category_ny].reset_index(drop=True)\n",
        "X_ny_test = ny_test.drop(category_ny, axis=1).reset_index(drop=True)\n",
        "\n",
        "y_la_test = la_test[category_la].reset_index(drop=True)\n",
        "X_la_test = la_test.drop(category_la, axis=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp7vk06NVBbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_ny = StandardScaler()\n",
        "X_ny_train = scaler_ny.fit_transform(X_ny_train)\n",
        "X_ny_test = scaler_ny.transform(X_ny_test)\n",
        "\n",
        "scaler_la = StandardScaler()\n",
        "X_la_train = scaler_la.fit_transform(X_la_train)\n",
        "X_la_test = scaler_la.transform(X_la_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0U08A8lVCYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "nor_ny = Normalizer()\n",
        "X_ny_train = nor_ny.fit_transform(X_ny_train)\n",
        "X_ny_test = nor_ny.transform(X_ny_test)\n",
        "\n",
        "nor_la = Normalizer()\n",
        "X_la_train = nor_la.fit_transform(X_la_train)\n",
        "X_la_test = nor_la.transform(X_la_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBWyQczCVDZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ny_train = pd.DataFrame(data=X_ny_train,  columns = ny_columns[:33])\n",
        "for c_column in category_ny:\n",
        "    ny_train[c_column] = y_ny_train[c_column]\n",
        "\n",
        "\n",
        "la_train = pd.DataFrame(data=X_la_train,  columns=la_columns[:33])\n",
        "for c_column in category_la:\n",
        "    la_train[c_column] = y_la_train[c_column]\n",
        "\n",
        "\n",
        "ny_test= pd.DataFrame(data=X_ny_test,  columns=ny_columns[:33])\n",
        "for c_column in category_ny:\n",
        "    ny_test[c_column] = y_ny_test[c_column]\n",
        "\n",
        "\n",
        "la_test= pd.DataFrame(data=X_la_test,  columns=la_columns[:33])\n",
        "for c_column in category_la:\n",
        "    la_test[c_column] = y_la_test[c_column]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw3U3srCVEZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ny_train.to_csv( '{}/{}/{}'.format(source, city_ny, \"train_ny.csv\") ,index=False)\n",
        "ny_test.to_csv( '{}/{}/{}'.format(source, city_ny, \"test_ny.csv\") ,index=False)\n",
        "\n",
        "la_train.to_csv( '{}/{}/{}'.format(source, city_la, \"train_la.csv\") ,index=False)\n",
        "la_test.to_csv( '{}/{}/{}'.format(source, city_la, \"test_la.csv\") ,index=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miWG6RwCVIvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ny_reviews_df = pd.read_csv( '{}/{}/{}'.format(source, city_ny, f) )\n",
        "la_reviews_df = pd.read_csv( '{}/{}/{}'.format(source, city_la, f) )\n",
        "\n",
        "feature_selection = [\"street\" , \"neighbourhood_cleansed\", \"neighbourhood_group_cleansed\", \n",
        "                     \"city\", \"state\",  \"country\", \"zipcode\", \"latitude\", 'longitude', \"price\" ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rPO_JBkZmA6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sJDjqA0VljH",
        "colab_type": "text"
      },
      "source": [
        "# 2. Helper Functions for Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax-5qF1YV4Mw",
        "colab_type": "text"
      },
      "source": [
        "## Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-sG7R3PV537",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "import seaborn as sn\n",
        "temp = pd.concat([X_ny_train, y_ny_train], axis=1)\n",
        "# display(temp.head(10))\n",
        "\n",
        "# display(y_ny_train)\n",
        "\n",
        "corrMatrix = temp.corr()\n",
        "# print(corrMatrix.iloc[:,-1].sort_values())\n",
        "for ind in corrMatrix.iloc[:,-1].sort_values().index.tolist():\n",
        "  # ind = corrMatrix.index.tolist()[i]\n",
        "  # print(ind)\n",
        "  print('{:50s}: \\t {}'.format(ind, corrMatrix.loc[ind, 'price']))\n",
        "\n",
        "sn.heatmap(np.ravel(corrMatrix.iloc[:,-1]).reshape(len(corrMatrix), 1), annot=True)\n",
        "# sn.heatmap(corrMatrix, annot=True)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ9xH3MOV8xE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_to_drop = ['latitude', 'longitude', 'zipcode']\n",
        "# sub_X_la_train = X_la_train.drop(features_to_drop, axis=1)\n",
        "# display(sub_X_la_train.head(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIanDwhsWrGO",
        "colab_type": "text"
      },
      "source": [
        "## Testing Process Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6HK0XmQWnPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "import graphviz \n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNGBTirUXizm",
        "colab_type": "text"
      },
      "source": [
        "### Scatter Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRRcMHcAWnJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scatter_plot(y_test, y_test_pred, y_train, y_train_pred, model_name):\n",
        "    '''\n",
        "    A scatterplot of predicted vs. actual values \n",
        "    with a line representing where predicted = actual values\n",
        "    '''\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    fig.suptitle(str('Predicted vs. actual values - '+model_name), fontsize=14, y=1)\n",
        "    plt.subplots_adjust(top=0.93, wspace=0)\n",
        "    \n",
        "    ax1.scatter(y_test, y_test_pred, s=2, alpha=0.7)\n",
        "    ax1.plot(list(range(0,450)), list(range(50,500)), color='blue', linestyle='dashdot') \n",
        "    ax1.plot(list(range(0,500)), list(range(0,500)), color='black', linestyle='--')\n",
        "    ax1.plot(list(range(50,500)), list(range(0,450)), color='blue', linestyle='dashdot')\n",
        "    \n",
        "    ax1.set_title('Test set')\n",
        "    ax1.set_xlabel('Actual values')\n",
        "    ax1.set_ylabel('Predicted values')\n",
        "    \n",
        "    ax2.scatter(y_train, y_train_pred, s=2, alpha=0.7)\n",
        "    ax2.plot(list(range(0,450)), list(range(50,500)), color='blue', linestyle='dashdot')    \n",
        "    ax2.plot(list(range(0,500)), list(range(0,500)), color='black', linestyle='--')\n",
        "    ax2.plot(list(range(50,500)), list(range(0,450)), color='blue', linestyle='dashdot')\n",
        "    ax2.set_title('Train set')\n",
        "    ax2.set_xlabel('Actual values')\n",
        "    ax2.set_ylabel('')\n",
        "    ax2.set_yticklabels(labels='')\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhikIulJWwzB",
        "colab_type": "text"
      },
      "source": [
        "### Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_2vpDEJWv4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate 3 plots: the test and training learning curve, the training\n",
        "    samples vs fit times curve, the fit times vs score curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    axes : array of 3 axes, optional (default=None)\n",
        "        Axes to use for plotting the curves.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 5-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - :term:`CV splitter`,\n",
        "          - An iterable yielding (train, test) splits as arrays of indices.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : int or None, optional (default=None)\n",
        "        Number of jobs to run in parallel.\n",
        "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
        "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
        "        for more details.\n",
        "\n",
        "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the dtype is float, it is regarded as a\n",
        "        fraction of the maximum size of the training set (that is determined\n",
        "        by the selected validation method), i.e. it has to be within (0, 1].\n",
        "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
        "        Note that for classification the number of samples usually have to\n",
        "        be big enough to contain at least one sample from each class.\n",
        "        (default: np.linspace(0.1, 1.0, 5))\n",
        "    \"\"\"\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes,\n",
        "                       return_times=True)\n",
        "\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    fit_times_mean = np.mean(fit_times, axis=1)\n",
        "    fit_times_std = np.std(fit_times, axis=1)\n",
        "\n",
        "\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.suptitle(title)\n",
        "\n",
        "\n",
        "    return plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT8kAd80VJpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ny_price = ny_reviews_df[feature_selection]\n",
        "la_price = la_reviews_df[feature_selection]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggwJ1EQ5VKdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ny_price[\"city\"] = \"New York\"\n",
        "ny_price[\"state\"] = \"New York\"\n",
        "ny_price[\"country\"] = \"United States\"\n",
        "\n",
        "print(ny_price.isnull().sum(axis=0)/ny_price.shape[0])\n",
        "display(ny_price)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EFXLlsPVLrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "la_price[\"city\"] = \"Los Angeles\"\n",
        "la_price[\"state\"] = \"California\"\n",
        "la_price[\"country\"] = \"United States\"\n",
        "\n",
        "print(la_price.isnull().sum(axis=0)/la_price.shape[0])\n",
        "display(la_price)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTLu_E8tVNR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ny_price.to_csv( '{}/{}/{}'.format(source, city_ny, \"ny_price.csv\") ,index=False)\n",
        "la_price.to_csv( '{}/{}/{}'.format(source, city_la, \"la_price.csv\") ,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ3j-_CrV1_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeUDMq8mV-hA",
        "colab_type": "text"
      },
      "source": [
        "## Training Process Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoETPn-gWAfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, X_train, y_train):\n",
        "  \n",
        "  %time model.fit(X_train, y_train)\n",
        "\n",
        "  r2_score_cv = cross_val_score(model, X_train, y_train, scoring='r2', cv=3)\n",
        "  print('average r2 score: {},\\t cross-validation: {}'.format(np.mean(r2_score_cv), r2_score_cv))\n",
        "\n",
        "  mse_score_cv = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=3)\n",
        "  print('average mse score: {},\\t cross-validation: {}'.format(np.mean(mse_score_cv), mse_score_cv))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owy1GRQeZPdD",
        "colab_type": "text"
      },
      "source": [
        "# 3. Training & Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "077FElm2WCS6",
        "colab_type": "text"
      },
      "source": [
        "## Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI118zreWEfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# Train with randomized grid search\n",
        "\n",
        "\n",
        "''' class sklearn.tree.DecisionTreeRegressor(\n",
        "  criterion='mse', \n",
        "  splitter='best', \n",
        "  max_depth=None, \n",
        "  min_samples_split=2, \n",
        "  min_samples_leaf=1, \n",
        "  min_weight_fraction_leaf=0.0, \n",
        "  max_features=None, \n",
        "  random_state=None, \n",
        "  max_leaf_nodes=None, \n",
        "  min_impurity_decrease=0.0, \n",
        "  min_impurity_split=None, \n",
        "  presort='deprecated', \n",
        "  ccp_alpha=0.0)\n",
        "'''\n",
        "\n",
        "parameters = {  'max_depth' : list(range(10,200,10)),\n",
        "                'criterion' : ['mae'],\n",
        "                'min_samples_leaf' : [3, 8, 20, 30, 50, 70, 100],\n",
        "                'min_samples_split' : [3, 8, 20, 50, 80, 100]\n",
        "              }\n",
        "\n",
        "clf = RandomizedSearchCV(tree.DecisionTreeRegressor(), parameters, n_iter=40, cv=5)\n",
        "clf.fit(X_la_train.drop(features_to_drop, axis=1), y_la_train)\n",
        "\n",
        "results_df = pd.DataFrame(clf.cv_results_)\n",
        "display(results_df)\n",
        "\n",
        "print('best score: ', clf.best_score_)\n",
        "print('best parameters: ', clf.best_params_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usAMYJdPWHtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Decision Tree\n",
        "\n",
        "best = clf.best_estimator_\n",
        "print(best)\n",
        "\n",
        "print('Decision Tree Test Scores:')\n",
        "\n",
        "print('Training: ')\n",
        "print('r2 score:  \\t{}'.format(r2_score(best.predict(X_la_train), y_la_train)))\n",
        "print('mse score: \\t{}'.format(mean_squared_error(best.predict(X_la_train), y_la_train)))\n",
        "print('mae score: \\t{}'.format(mean_absolute_error(best.predict(X_la_train), y_la_train)))\n",
        "\n",
        "print('Testing: ')\n",
        "print('r2 score:  \\t{}'.format(r2_score(best.predict(X_la_test), y_la_test)))\n",
        "print('mse score: \\t{}'.format(mean_squared_error(best.predict(X_la_test), y_la_test)))\n",
        "print('mae score: \\t{}'.format(mean_absolute_error(best.predict(X_la_test), y_la_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4uKvpmKWJhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # visualize ccp_alpha effect on post-pruning \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path = best.cost_complexity_pruning_path(X_ny_train, y_ny_train)\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
        "ax.set_xlabel(\"effective alpha\")\n",
        "ax.set_ylabel(\"total impurity of leaves\")\n",
        "ax.set_title(\"Total Impurity vs effective alpha for training set\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JibAF7N0WKwD",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4AB26uoWKHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('''Random Forest''')\n",
        "\n",
        "'''\n",
        "class sklearn.ensemble.RandomForestRegressor(\n",
        "  n_estimators=100, \n",
        "  criterion='mse', \n",
        "  max_depth=None, \n",
        "  min_samples_split=2, \n",
        "  min_samples_leaf=1, \n",
        "  min_weight_fraction_leaf=0.0, \n",
        "  max_features='auto', \n",
        "  max_leaf_nodes=None, \n",
        "  min_impurity_decrease=0.0, \n",
        "  min_impurity_split=None, \n",
        "  bootstrap=True, \n",
        "  oob_score=False, \n",
        "  n_jobs=None, \n",
        "  random_state=None, \n",
        "  verbose=0, \n",
        "  warm_start=False, \n",
        "  ccp_alpha=0.0, \n",
        "  max_samples=None)\n",
        "'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=10, max_depth=3, min_samples_split=10)\n",
        "model_randomforest_ny = train_model(model, X_ny_train, y_ny_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpzxrKCLWPQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# Train with randomized grid search\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "parameters = {  'n_estimators': [100, 150, 200],\n",
        "                'max_depth' : list(range(2,20,3)),\n",
        "                'min_samples_leaf' : [1, 2, 3, 5, 8, 10, 15, 20],\n",
        "                'min_samples_split' : [1, 2, 3, 5, 8, 10, 15, 20],\n",
        "                'ccp_alpha' : [0, 0.2, 0.5, 1, 10, 30, 60, 100]\n",
        "              }\n",
        "\n",
        "clf = RandomizedSearchCV(RandomForestRegressor(), parameters, n_iter=20, cv=2)\n",
        "clf.fit(X_la_train, np.ravel(y_la_train))\n",
        "\n",
        "results_df = pd.DataFrame(clf.cv_results_)\n",
        "display(results_df)\n",
        "# display(results_df[['param_max_depth', 'mean_test_score']])\n",
        "\n",
        "print(clf.best_score_)\n",
        "print(clf.best_params_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu6Lf5MDWQOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Random Forest\n",
        "\n",
        "best = clf.best_estimator_\n",
        "print(best)\n",
        "\n",
        "print('Random Forest Test Scores:')\n",
        "\n",
        "print('Training: ')\n",
        "print('r2 score:  \\t{}'.format(r2_score(best.predict(X_la_train), y_la_train)))\n",
        "print('mse score: \\t{}'.format(mean_squared_error(best.predict(X_la_train), y_la_train)))\n",
        "print('mae score: \\t{}'.format(mean_absolute_error(best.predict(X_la_train), y_la_train)))\n",
        "\n",
        "print('Testing: ')\n",
        "print('r2 score:  \\t{}'.format(r2_score(best.predict(X_la_test), y_la_test)))\n",
        "print('mse score: \\t{}'.format(mean_squared_error(best.predict(X_la_test), y_la_test)))\n",
        "print('mae score: \\t{}'.format(mean_absolute_error(best.predict(X_la_test), y_la_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WRETKYfWRcj",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTl2SzIuWS67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "model = linear_model.Ridge(alpha=.5)\n",
        "model = model.fit(X_ny_train, y_ny_train)\n",
        "model_linear_ny = train_model(model, X_ny_train, y_ny_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61F8bnh5WT5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def test_linear(model, X_test, y_test, X_train, y_train, title):\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    mse = mean_squared_error(y_test, y_test_pred)\n",
        "    r2 = r2_score(y_test, y_test_pred)\n",
        "    mae = mean_absolute_error(y_test, y_test_pred)\n",
        "    print(\"mse score is: \" + str(mse))\n",
        "    print(\"r2 score is: \" + str(r2))\n",
        "    print(\"mae score is: \" + str(mae))\n",
        "  \n",
        "    scatter_plot(y_test, y_test_pred, y_train, y_train_pred,title)\n",
        "    return (mse, r2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-LeuMJYWXSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_linear(model_linear_ny, X_ny_test,y_ny_test, X_ny_train,y_ny_train,\"Linear\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nVwtXVUWYGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title = \"Learning Curves (Linear Regression)\"\n",
        "plt = plot_learning_curve(model_linear_ny, title, X_ny_train, y_ny_train, axes=None, ylim=None, cv= 5)\n",
        "plt.savefig(\"Linear_learning_curve.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW21liVEWVGx",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt1ovWoaWcUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "def test_NN(model,skip_epochs, X_test, y_test, X_train, y_train, title):\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    mse = mean_squared_error(y_test, y_test_pred)\n",
        "    r2 = r2_score(y_test, y_test_pred)\n",
        "    mae = mean_absolute_error(y_test, y_test_pred)\n",
        "    print(\"mse score is: \" + str(mse))\n",
        "    print(\"r2 score is: \" + str(r2))\n",
        "    print(\"mae score is: \" + str(mae))\n",
        "   \n",
        "    # Line graph of losses\n",
        "    model_results = model.history.history\n",
        "    plt.plot(list(range((skip_epochs+1),len(model_results['loss'])+1)), model_results['loss'][skip_epochs:], label='Train',color='red')\n",
        "    plt.plot(list(range((skip_epochs+1),len(model_results['val_loss'])+1)), model_results['val_loss'][skip_epochs:], label='Test', color='green')\n",
        "    plt.legend()\n",
        "    plt.title('Learning Curves(Neural Network)', fontsize=14)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"MSE Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    scatter_plot(y_test, y_test_pred, y_train, y_train_pred, title)   \n",
        "    return (mse, r2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_WiniQ7Wdfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models, layers, optimizers, regularizers\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "# Building the model\n",
        "nn_ny = models.Sequential()\n",
        "nn_ny.add(layers.Dropout(0.2, input_shape=(X_ny_train.shape[1],)))\n",
        "nn_ny.add(layers.Dense(128, activation='relu'))\n",
        "nn_ny.add(layers.Dropout(0.2))\n",
        "nn_ny.add(layers.Dense(256, activation='relu'))\n",
        "nn_ny.add(layers.Dropout(0.2))\n",
        "nn_ny.add(layers.Dense(512, activation='relu'))\n",
        "nn_ny.add(layers.Dropout(0.2))\n",
        "nn_ny.add(layers.Dense(1, activation='linear'))\n",
        "\n",
        "# Compiling the model\n",
        "nn_ny.compile(loss='mean_squared_error',\n",
        "            optimizer='adam',\n",
        "            metrics=['mean_squared_error'])\n",
        "\n",
        "# Model summary\n",
        "print(nn_ny.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni2JeEwqWfwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "# Training the model\n",
        "nn_ny_start = time.time()\n",
        "\n",
        "nn_ny_history = nn_ny.fit(X_ny_train,\n",
        "                  y_ny_train,\n",
        "                  epochs=200,\n",
        "                  batch_size=200,\n",
        "                  validation_split = 0.1)\n",
        "\n",
        "nn_ny_end = time.time()\n",
        "\n",
        "print(f\"Time taken to run: {round((nn_ny_end - nn_ny_start)/60,1)} minutes\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il2jyiCvWg9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_NN(nn_ny,20, X_ny_test,y_ny_test, X_ny_train,y_ny_train, \"NN\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj4RrRBjWfi5",
        "colab_type": "text"
      },
      "source": [
        "## KNN Regressor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cJfbXfFWk2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def train_KNN(model, X, y):\n",
        "    model = model.fit(X, y)\n",
        "    print(\"training r2: \" + str(model.score(X,y)))\n",
        "    return model\n",
        "\n",
        "def train_test_KNN(model, X_test, y_test, X_train, y_train, model_name):\n",
        "    model = train_KNN(model, X_train, y_train)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "    print(\"training mse: \" + str(train_mse))\n",
        "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "    print(\"training mae: \" + str(train_mae))\n",
        "\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_test_pred)\n",
        "    r2 = r2_score(y_test, y_test_pred)\n",
        "    mae = mean_absolute_error(y_test, y_test_pred)\n",
        "    print(\"mse score is: \" + str(mse))\n",
        "    print(\"r2 score is: \" + str(r2))\n",
        "    print(\"mae score is: \" + str(mae))\n",
        "\n",
        "    scatter_plot(y_test, y_test_pred, y_train, y_train_pred, model_name)\n",
        "    return (mse, r2, mae)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-zYwzs_WmbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ny = KNeighborsRegressor( n_neighbors=25, p = 1)\n",
        "train_test_KNN(model_ny, subdataX_test_ny, y_ny_test, subdataX_train_ny, y_ny_train, \"KNN\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}